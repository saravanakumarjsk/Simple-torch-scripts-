{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled15.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saravanakumarjsk/Simple-torch-scripts-/blob/master/cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSTSFVGG-eno",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "device = 'cuda'\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZ8wVPwc-3nj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "904e212e-7b37-44d0-e425-691562fc6714"
      },
      "source": [
        "import torchvision\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as t\n",
        "\n",
        "transforms = t.Compose([t.RandomHorizontalFlip(),\n",
        "                       t.RandomRotation(10),\n",
        "                       t.ToTensor(),\n",
        "                       t.Normalize((0.5, 0.5, 0.5),\n",
        "                                  (0.5, 0.5, 0.5))])\n",
        "\n",
        "traindata = datasets.CIFAR10('data', train = True, download = True, transform = transforms)\n",
        "testdata = datasets.CIFAR10('data', train = False, download = True, transform = transforms)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZYUUBDiADzC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2cc0c860-981b-4eaf-8807-54c2afc45417"
      },
      "source": [
        "train_len = len(traindata)\n",
        "print(train_len)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LJlATX_BFJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqdrsPM_AX9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index = list(range(train_len))\n",
        "np.random.shuffle(index)\n",
        "split = int(np.floor(train_len * 0.2))\n",
        "train_index, val_index = index[split:], index[:split]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUQ2x8CLBZKN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data.sampler import SubsetRandomSampler as s\n",
        "\n",
        "train_sampler = s(train_index)\n",
        "valid_sampler = s(val_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5y70wGwCGBn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(traindata, \n",
        "                                           batch_size = 16,\n",
        "                                           sampler = train_sampler,\n",
        "                                          num_workers = 4)\n",
        "\n",
        "valid_loader = torch.utils.data.DataLoader(traindata, \n",
        "                                          batch_size = 16,\n",
        "                                          sampler = valid_sampler,\n",
        "                                          num_workers = 4)\n",
        "\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(testdata, \n",
        "                                           batch_size = 16,\n",
        "                                          num_workers = 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNP-eqCOCJsX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "images = images.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDiFgXj_EqbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlI3BcCBDmfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# %matplotlib inline\n",
        "\n",
        "# # helper function to un-normalize and display an image\n",
        "# def imshow(img):\n",
        "#     img = img / 2 + 0.5  # unnormalize\n",
        "#     plt.imshow(np.transpose(img, (1, 2, 0)))  # convert from Tensor image\n",
        "\n",
        "\n",
        "# # plot the images in the batch, along with the corresponding labels\n",
        "# fig = plt.figure(figsize=(25, 4))\n",
        "# # display 20 images\n",
        "# for idx in np.arange(20):\n",
        "#     ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
        "#     imshow(images[idx])\n",
        "#     ax.set_title(classes[labels[idx]])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Btfsa6LrDnaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as f\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        \n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        #64*4*4\n",
        "        self.fc1 = nn.Linear(1024, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "        \n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "    def forward(self, x):\n",
        "        x = self.pool(f.relu(self.conv1(x)))\n",
        "        x = self.pool(f.relu(self.conv2(x)))\n",
        "        x = self.pool(f.relu(self.conv3(x)))\n",
        "        \n",
        "        x = x.view(-1, 1024)\n",
        "        x = self.dropout(x)\n",
        "        \n",
        "        x = f.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiQj48VSG1-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdCNJ__GG3s1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "55b7c2e8-e978-46c6-8b4a-75e10a95ee87"
      },
      "source": [
        "model = Net()\n",
        "model.to(device)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
              "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHmp_kZpG8CT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFxf-LjVH629",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 924
        },
        "outputId": "44138c2f-34d9-4805-dd2e-a6d43f1e0b56"
      },
      "source": [
        "val_loss_min = np.Inf\n",
        "\n",
        "for epoch in range(1, 40):\n",
        "    \n",
        "    val_loss = 0.0\n",
        "    train_loss = 0.0\n",
        "    model.train()\n",
        "    \n",
        "    for idx, (images, labels) in enumerate(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss += loss.item()\n",
        "        \n",
        "        model.eval()\n",
        "    for idx, (images, labels) in enumerate(valid_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        \n",
        "        val_loss += loss.item()\n",
        "        \n",
        "    train_loss = train_loss/len(train_loader.sampler)\n",
        "    val_loss = val_loss/len(valid_loader.sampler)\n",
        " \n",
        "\n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        epoch, train_loss, val_loss))\n",
        "    \n",
        "    # save model if validation loss has decreased\n",
        "    if val_loss <= val_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        val_loss_min,\n",
        "        val_loss))\n",
        "        torch.save(model.state_dict(), 'model_augmented.pt')\n",
        "        val_loss_min = val_loss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.126553 \tValidation Loss: 0.106421\n",
            "Validation loss decreased (inf --> 0.106421).  Saving model ...\n",
            "Epoch: 2 \tTraining Loss: 0.097543 \tValidation Loss: 0.089855\n",
            "Validation loss decreased (0.106421 --> 0.089855).  Saving model ...\n",
            "Epoch: 3 \tTraining Loss: 0.086630 \tValidation Loss: 0.084010\n",
            "Validation loss decreased (0.089855 --> 0.084010).  Saving model ...\n",
            "Epoch: 4 \tTraining Loss: 0.079189 \tValidation Loss: 0.078108\n",
            "Validation loss decreased (0.084010 --> 0.078108).  Saving model ...\n",
            "Epoch: 5 \tTraining Loss: 0.073029 \tValidation Loss: 0.073278\n",
            "Validation loss decreased (0.078108 --> 0.073278).  Saving model ...\n",
            "Epoch: 6 \tTraining Loss: 0.067658 \tValidation Loss: 0.069557\n",
            "Validation loss decreased (0.073278 --> 0.069557).  Saving model ...\n",
            "Epoch: 7 \tTraining Loss: 0.063272 \tValidation Loss: 0.062688\n",
            "Validation loss decreased (0.069557 --> 0.062688).  Saving model ...\n",
            "Epoch: 8 \tTraining Loss: 0.059665 \tValidation Loss: 0.062275\n",
            "Validation loss decreased (0.062688 --> 0.062275).  Saving model ...\n",
            "Epoch: 9 \tTraining Loss: 0.056055 \tValidation Loss: 0.057277\n",
            "Validation loss decreased (0.062275 --> 0.057277).  Saving model ...\n",
            "Epoch: 10 \tTraining Loss: 0.053206 \tValidation Loss: 0.056007\n",
            "Validation loss decreased (0.057277 --> 0.056007).  Saving model ...\n",
            "Epoch: 11 \tTraining Loss: 0.050542 \tValidation Loss: 0.055432\n",
            "Validation loss decreased (0.056007 --> 0.055432).  Saving model ...\n",
            "Epoch: 12 \tTraining Loss: 0.048259 \tValidation Loss: 0.052877\n",
            "Validation loss decreased (0.055432 --> 0.052877).  Saving model ...\n",
            "Epoch: 13 \tTraining Loss: 0.046092 \tValidation Loss: 0.052695\n",
            "Validation loss decreased (0.052877 --> 0.052695).  Saving model ...\n",
            "Epoch: 14 \tTraining Loss: 0.044086 \tValidation Loss: 0.051919\n",
            "Validation loss decreased (0.052695 --> 0.051919).  Saving model ...\n",
            "Epoch: 15 \tTraining Loss: 0.042252 \tValidation Loss: 0.050015\n",
            "Validation loss decreased (0.051919 --> 0.050015).  Saving model ...\n",
            "Epoch: 16 \tTraining Loss: 0.040495 \tValidation Loss: 0.049512\n",
            "Validation loss decreased (0.050015 --> 0.049512).  Saving model ...\n",
            "Epoch: 17 \tTraining Loss: 0.038858 \tValidation Loss: 0.048346\n",
            "Validation loss decreased (0.049512 --> 0.048346).  Saving model ...\n",
            "Epoch: 18 \tTraining Loss: 0.037297 \tValidation Loss: 0.049481\n",
            "Epoch: 19 \tTraining Loss: 0.035857 \tValidation Loss: 0.049142\n",
            "Epoch: 20 \tTraining Loss: 0.034760 \tValidation Loss: 0.050266\n",
            "Epoch: 21 \tTraining Loss: 0.033340 \tValidation Loss: 0.049195\n",
            "Epoch: 22 \tTraining Loss: 0.031944 \tValidation Loss: 0.047980\n",
            "Validation loss decreased (0.048346 --> 0.047980).  Saving model ...\n",
            "Epoch: 23 \tTraining Loss: 0.030546 \tValidation Loss: 0.051233\n",
            "Epoch: 24 \tTraining Loss: 0.029692 \tValidation Loss: 0.050897\n",
            "Epoch: 25 \tTraining Loss: 0.028538 \tValidation Loss: 0.048440\n",
            "Epoch: 26 \tTraining Loss: 0.027399 \tValidation Loss: 0.050905\n",
            "Epoch: 27 \tTraining Loss: 0.026534 \tValidation Loss: 0.048740\n",
            "Epoch: 28 \tTraining Loss: 0.025475 \tValidation Loss: 0.053020\n",
            "Epoch: 29 \tTraining Loss: 0.024611 \tValidation Loss: 0.049386\n",
            "Epoch: 30 \tTraining Loss: 0.023317 \tValidation Loss: 0.052817\n",
            "Epoch: 31 \tTraining Loss: 0.022711 \tValidation Loss: 0.051810\n",
            "Epoch: 32 \tTraining Loss: 0.022085 \tValidation Loss: 0.053794\n",
            "Epoch: 33 \tTraining Loss: 0.020915 \tValidation Loss: 0.053812\n",
            "Epoch: 34 \tTraining Loss: 0.020116 \tValidation Loss: 0.054349\n",
            "Epoch: 35 \tTraining Loss: 0.019387 \tValidation Loss: 0.057174\n",
            "Epoch: 36 \tTraining Loss: 0.018717 \tValidation Loss: 0.056812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-OIWumTIBTm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_state_dict(torch.load('model_augmented.pt'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krf5G9OAJHMI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# track test loss\n",
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "model.eval()\n",
        "# iterate over test data\n",
        "for batch_idx, (data, target) in enumerate(test_loader):\n",
        "    # move tensors to GPU if CUDA is available\n",
        "    if train_on_gpu:\n",
        "        data, target = data.cuda(), target.cuda()\n",
        "    # forward pass: compute predicted outputs by passing inputs to the model\n",
        "    output = model(data)\n",
        "    # calculate the batch loss\n",
        "    loss = criterion(output, target)\n",
        "    # update test loss \n",
        "    test_loss += loss.item()*data.size(0)\n",
        "    # convert output probabilities to predicted class\n",
        "    _, pred = torch.max(output, 1)    \n",
        "    # compare predictions to true label\n",
        "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "    # calculate test accuracy for each object class\n",
        "    for i in range(batch_size):\n",
        "        label = target.data[i]\n",
        "        class_correct[label] += correct[i].item()\n",
        "        class_total[label] += 1\n",
        "\n",
        "# average test loss\n",
        "test_loss = test_loss/len(test_loader.dataset)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "for i in range(10):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            classes[i], 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}